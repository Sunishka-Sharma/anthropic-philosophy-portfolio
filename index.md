---
layout: default
title: Selected Philosophy Papers for Anthropic
description: Philosophy and AI Ethics Portfolio (2020-2024)
---

# **Selected Philosophy Papers for Anthropic**

These papers were written between 2020–2024 during my undergraduate coursework in philosophy and AI ethics at IIIT-Delhi. Each explores topics related to value alignment, model behavior, and algorithmic accountability. I've selected these as part of my application to Anthropic's Model Behavior Architect role. For questions about authorship or academic context, feel free to reach out directly.

---

## <span class="emoji-icon">🔥</span> **CORE PORTFOLIO** 

<div class="paper-entry core-portfolio">
<h3>1. Algorithmic Accountability and Public Reason: A Critical Analysis</h3>

<p><span class="emoji-icon">📅</span> Second Year (Spring 2021) — Response Paper<br>  
<span class="emoji-icon">🧠</span> <strong>Novelty:</strong> Challenges a cutting-edge governance proposal; critiques Reuben Binns' use of Rawlsian "public reason" in AI.<br>
<span class="emoji-icon">✍️</span> <strong>Description:</strong> Engages deeply with Binns' framework, summarizing and critiquing his argument for public reason in algorithm design. The paper argues that "public reason" relies on contested assumptions, questioning its feasibility in practice. Thoughtfully challenges whether consensus-driven governance is realistic for AI alignment.</p>

<p><span class="emoji-icon">🔢</span> ~2200 words<br>
<span class="emoji-icon">💡</span> <strong>Strengths:</strong> Directly relevant to AI alignment. Demonstrates theoretical sophistication and policy-level reasoning.</p>

<a href="https://drive.google.com/file/d/1PTOpTGkJbjLwWsw8EMRLbTzwkWb8lErw/view?usp=drive_link" class="download-link" target="_blank">Download PDF</a>
</div>

<div class="paper-entry core-portfolio">
<h3>2. Family Vlogging and YouTube's Algorithm: A Disclosive Ethical Analysis</h3>

<p><span class="emoji-icon">📅</span> Second Year (Spring 2021) — Case Study<br>
<span class="emoji-icon">🧠</span> <strong>Novelty:</strong> Applies Brey's disclosive ethics to algorithmic incentives in the YouTube recommender system—a rare methodological application.<br>
<span class="emoji-icon">✍️</span> <strong>Description:</strong> Investigates how YouTube's engagement-optimizing algorithm incentivizes exploitative family vlogs. Applies a two-stage disclosive analysis to reveal the platform's hidden value priorities. Highlights algorithmic harm to vulnerable users and draws powerful analogies to child labor law.</p>

<p><span class="emoji-icon">🔢</span> ~1500 words<br>
<span class="emoji-icon">💡</span> <strong>Strengths:</strong> Original lens, well-researched, Medium-ready. A strong example of applied ethical critique of model behavior.</p>

<a href="https://drive.google.com/file/d/1NG3EkbEQwWVLsxvn3RE_myQqt9p77tMH/view?usp=drive_link" class="download-link" target="_blank">Download PDF</a>
</div>

<div class="paper-entry core-portfolio">
<h3>3. Beyond Humans: The Case for Animals in AI Ethics</h3>

<p><span class="emoji-icon">📅</span> Third Year (Spring 2023) — Academic Review (Primary author)<br>
<span class="emoji-icon">🧠</span> <strong>Novelty:</strong> Expands alignment discourse beyond humans; critiques species bias in datasets and model design.<br>
<span class="emoji-icon">✍️</span> <strong>Description:</strong> Synthesizes multiple sources to argue for including non-human animal welfare in AI ethics. Challenges anthropocentrism in alignment goals. Offers a rare lens on overlooked stakeholders in AI systems.</p>

<p><span class="emoji-icon">🔢</span> ~3000 words<br>
<span class="emoji-icon">💡</span> <strong>Strengths:</strong> Strong moral imagination, original scope, and excellent command of ethics literature. Medium-ready.</p>

<a href="https://drive.google.com/file/d/121u8XOzoqOozbS9-eAY0E4ejBK9jrOAY/view?usp=drive_link" class="download-link" target="_blank">Download PDF</a>
</div>

<div class="paper-entry core-portfolio">
<h3>4. The Ethics of Family Vlogging: A Just Consequentialist Perspective</h3>

<p><span class="emoji-icon">📅</span> Second Year (Fall 2021) — Position Paper<br>
<span class="emoji-icon">🧠</span> <strong>Novelty:</strong> Applies James Moor's "just consequentialism" to the ethics of monetized family content online.<br>
<span class="emoji-icon">✍️</span> <strong>Description:</strong> Critically evaluates the ethics of YouTube family vlogs using a balanced theoretical framework. Argues that even well-intended family vlogging erodes children's autonomy, privacy, and dignity, with long-term harms outweighing immediate gains.</p>

<p><span class="emoji-icon">🔢</span> ~600 words<br>
<span class="emoji-icon">💡</span> <strong>Strengths:</strong> Highly readable, ethical clarity, Medium-ready. Bridges formal ethics and pop culture critique.</p>

<a href="https://drive.google.com/file/d/1kpuqx-gonj1QjyDLaNmOKuJSCbVjUWTO/view?usp=drive_link" class="download-link" target="_blank">Download PDF</a>
</div>

<div class="paper-entry core-portfolio">
<h3>5. Autonomy and Free Will in the Digital Age</h3>

<p><span class="emoji-icon">📅</span> 3rd Year (Spring 2023) — Reflective Essay<br>
<span class="emoji-icon">🧠</span> <strong>Novelty:</strong> Reinterprets classical autonomy theory (Mill, Berlin) in light of algorithmic manipulation.<br>
<span class="emoji-icon">✍️</span> <strong>Description:</strong> Argues that recommender systems and targeted ads covertly manipulate users' choices, echoing past propaganda tools. Balances historical continuity with modern concerns about digital freedom and behavioral nudging.</p>

<p><span class="emoji-icon">🔢</span> ~2100 words<br>
<span class="emoji-icon">💡</span> <strong>Strengths:</strong> Strong value analysis of covert influence. Makes philosophical foundations accessible.</p>

<a href="https://docs.google.com/document/d/1pP4e4TLispG1Rc4hI_mxd3hFJ5BI8nhYbuJUFFDwEuo/edit?usp=drive_link" class="download-link" target="_blank">View Document</a>
</div>

---

## <span class="emoji-icon">💡</span> **INTERESTING ADDITIONS — Optional for Broader Ethical Context**

<div class="paper-entry additions">
<h3>6. Why AI Is Not Neutral: Bias and the Black-Box Problem</h3>

<p><span class="emoji-icon">📅</span> Third Year (Fall 2022) — Midsemester response paper<br>
<span class="emoji-icon">🧠</span> <strong>Novelty:</strong> Insightful twist on algorithmic classification bias beyond human error.<br>
<span class="emoji-icon">✍️</span> <strong>Description:</strong> Uses real-world examples to demonstrate why even technically sound AI systems perpetuate bias. Argues that classification itself introduces distortion, regardless of human prejudice.</p>

<p><span class="emoji-icon">🔢</span> ~2300 words<br>
<span class="emoji-icon">💡</span> <strong>Strengths:</strong> Solid foundations in bias and accountability. Strong early instincts about AI opacity.</p>

<a href="https://drive.google.com/file/d/1wMsRnP6Vmde-5nftdSbO5kaO1IrfFubM/view?usp=drive_link" class="download-link" target="_blank">Download PDF</a>
</div>

<div class="paper-entry additions">
<h3>7. The Limits of Utilitarianism in Public Policy</h3>

<p><span class="emoji-icon">📅</span> 2nd Year (Fall 2021) — Mid-Sem Paper<br>
<span class="emoji-icon">🧠</span> <strong>Novelty:</strong> Analyzes collapse between act and rule utilitarianism in political decision-making.<br>
<span class="emoji-icon">✍️</span> <strong>Description:</strong> Questions the viability of utilitarian frameworks in democratic governance. Uses classic thought experiments to explore how utility-maximization can conflict with justice, rights, and social trust.</p>

<p><span class="emoji-icon">🔢</span> ~1800 words<br>
<span class="emoji-icon">💡</span> <strong>Strengths:</strong> Strong theoretical engagement and structured reasoning. Useful to show moral depth.</p>

<a href="https://drive.google.com/file/d/10VJw_3xx8FjEMjOd12VNX1kAk8hGLLpo/view?usp=drive_link" class="download-link" target="_blank">Download PDF</a>
</div>

<div class="paper-entry additions">
<h3>8. Drones and the Ethics of Remote Warfare</h3>

<p><span class="emoji-icon">📅</span> 3rd Year (Fall 2022) — End-Sem Paper<br>
<span class="emoji-icon">🧠</span> <strong>Novelty:</strong> Applies post-phenomenological frameworks (Ihde) and just consequentialism to remote warfare.<br>
<span class="emoji-icon">✍️</span> <strong>Description:</strong> Explores moral responsibility gaps in drone warfare. Examines how human-technology relationships change perceptions of harm and accountability in algorithmically-mediated conflict.</p>

<p><span class="emoji-icon">🔢</span> ~2100 words<br>
<span class="emoji-icon">💡</span> <strong>Strengths:</strong> Shows ability to handle high-stakes ethical trade-offs in tech. Less central to Anthropic, but impressive nonetheless.</p>

<a href="https://drive.google.com/file/d/16AoCjR9yFbNe7wehJwPEJBLdJREf4Jn3/view?usp=drive_link" class="download-link" target="_blank">Download PDF</a>
</div>

---

## <span class="emoji-icon">📎</span> **SUPPLEMENTAL — For Completeness or Footnotes**

<div class="paper-entry supplemental">
<h3>9. Ethical Challenges in the COVID-19 Vaccine Rollout <em>(Primary Author)</em></h3>

<p><span class="emoji-icon">📅</span> Second Year (Fall 2021)<br>
<span class="emoji-icon">🧠</span> <strong>Novelty:</strong> Comprehensive multi-theory evaluation of a real-time global crisis.<br>
<span class="emoji-icon">✍️</span> <strong>Description:</strong> Evaluates vaccine R&D, IP rights, and global equity through lenses of liberty, justice, and utilitarianism. Best included to demonstrate collaborative ethics work.</p>

<p><span class="emoji-icon">🔢</span> ~10000 words<br>
<span class="emoji-icon">💡</span> <strong>Strengths:</strong> Strong policy reasoning and teamwork. Less applicable to model alignment.</p>

<a href="https://docs.google.com/document/d/1WPXPdYcv_OflwX_WqrHXUj3qS58ZFT2BNgF-8r9C7fo/edit?usp=drive_link" class="download-link" target="_blank">View Document</a>
</div>

<div class="paper-entry supplemental">
<h3>10. Demystifying Actor-Network Theory (ANT)</h3>

<p><span class="emoji-icon">📅</span> Third Year (Spring 2023) — Reflection Paper<br>
<span class="emoji-icon">🧠</span> <strong>Novelty:</strong> Conceptual breakdown of Bruno Latour's ANT with simple metaphors.<br>
<span class="emoji-icon">✍️</span> <strong>Description:</strong> Explains key ANT concepts (actants, networks) using Jenga blocks and birthday cakes. Helpful to show theoretical range but unrelated to alignment.</p>

<p><span class="emoji-icon">🔢</span> ~1100 words<br>
<span class="emoji-icon">💡</span> <strong>Strengths:</strong> Accessible theory summary. Best suited as an appendix item.</p>

<a href="https://drive.google.com/file/d/1jFFMratstCdJtBsgHlJl7Xx8ocx8TIF0/view?usp=drive_link" class="download-link" target="_blank">Download PDF</a>
</div>

<div class="paper-entry supplemental">
<h3>11. Durkheim and the Division of Labour: Functionalism vs Structuralism</h3>

<p><span class="emoji-icon">📅</span> Final Year (Spring 2024) — Advanced Sociological Theory Response Paper<br>
<span class="emoji-icon">🧠</span> <strong>Novelty:</strong> Deconstructs Durkheim's work through both structuralist and functionalist lenses, offering a rare meta-theoretical synthesis.<br>
<span class="emoji-icon">✍️</span> <strong>Description:</strong> A detailed comparative analysis of Emile Durkheim's concept of the division of labour. Explores the intersection of structure and function by dividing Durkheim's arguments into structuralist and functionalist frames. Also critiques Durkheim's neglect of conflict and agency. Uses rich analogies (including programming metaphors) to explain abstract sociological theory in clear terms.</p>

<p><span class="emoji-icon">🔢</span> ~5300 words<br>
<span class="emoji-icon">💡</span> <strong>Strengths:</strong> Sophisticated grasp of theoretical categories. Excellent conceptual clarity. A unique philosophical take on classical theory.</p>

<a href="https://drive.google.com/file/d/1ggytzrhrqh6S9TCj8niaON4s_ymtXWkz/view?usp=drive_link" class="download-link" target="_blank">Download PDF</a>
</div>

---

## <span class="emoji-icon">🎓</span> **Coursework Distinctions in Philosophy**

I enrolled in **every philosophy elective offered at IIIT-Delhi** and received a **perfect GPA (10/10)** in all of them. These courses were taught by scholars with active research in ethics, philosophy of technology, and political theory.

Notably, IIIT-Delhi uses a **relative, weighted GPA system** — meaning GPA is not awarded based on absolute marks but on comparative performance. In these philosophy courses, **only two students** (myself included) received a GPA of 9 or above. I took these electives **alongside Master's and PhD students**, many of whom had extensive backgrounds in philosophy or the social sciences.

### <span class="emoji-icon">📘</span> **Philosophy Courses Completed with Distinction**

<div class="table-responsive">
<table>
  <thead>
    <tr>
      <th>Course Title</th>
      <th>Instructor</th>
      <th>Semester</th>
      <th>Grade</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Ethics in AI</strong></td>
      <td>Dr. Manohar Kumar</td>
      <td>Spring 2023</td>
      <td>A (10)</td>
    </tr>
    <tr>
      <td><strong>Philosophy of Technology</strong></td>
      <td>Dr. Nishad Patnaik</td>
      <td>Fall 2022</td>
      <td>A (10)</td>
    </tr>
    <tr>
      <td><strong>Social and Political Philosophy</strong></td>
      <td>Dr. Manohar Kumar</td>
      <td>Fall 2021</td>
      <td>A (10)</td>
    </tr>
    <tr>
      <td><strong>Theory and Practice of Engineering Ethics</strong></td>
      <td>Dr. Shweta Singh</td>
      <td>Spring 2021</td>
      <td>A (10)</td>
    </tr>
  </tbody>
</table>
</div>

Many of the ideas explored in these classrooms evolved into the writing samples featured in this portfolio. 